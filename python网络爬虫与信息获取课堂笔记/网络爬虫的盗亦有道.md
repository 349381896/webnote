# 一、网络爬虫的尺寸
- 爬取网页，玩转网页
    - 小规模，数据量小，爬取速度不敏感Request库
- 爬取网站，爬取系列网站
    - 中规模，数据量规模较大，爬取速度敏感Scrapy库
- 爬取全网
    - 大规模，搜素引擎，爬取速度是关键

# 二、robots协议

- robots协议基本语法
```
#注释，*代表所有，/代表目录
User-agent:*
Disallow:/
```
- robots协议路径
    - 域名/robots.txt
        - 例如：https://www.baidu.com/robts.txt